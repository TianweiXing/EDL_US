{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tianwei/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "import os\n",
    "import librosa\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1234\n",
    "tf.set_random_seed(seed)\n",
    "np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Logit to evidence converters - activation functions (they have to produce non-negative outputs for the uncertaintyuncertainity process)\n",
    "\n",
    "def relu_evidence(logits):\n",
    "    return tf.nn.relu(logits)\n",
    "\n",
    "# def exp_evidence(logits):                  # tune the parameters  1000\n",
    "#     return tf.exp(logits/1)\n",
    "\n",
    "# This one usually works better and used for the second and third examples\n",
    "# For general settings and different datasets, you may try this one first\n",
    "def exp_evidence(logits): \n",
    "    return tf.exp(tf.clip_by_value(logits,-10,10))\n",
    "\n",
    "\n",
    "\n",
    "def softplus(logits):\n",
    "    return tf.keras.activations.softplus(logits)\n",
    "  \n",
    "def relu6_evidence(logits):\n",
    "    return tf.nn.relu6(logits)\n",
    "  \n",
    "def softsign_evidence(logits):\n",
    "    return tf.nn.softsign(logits)\n",
    "\n",
    "  \n",
    "#### KL Divergence calculator\n",
    "\n",
    "def KL(alpha, K):\n",
    "    beta=tf.constant(np.ones((1,K)),dtype=tf.float32)\n",
    "    S_alpha = tf.reduce_sum(alpha,axis=1,keepdims=True)\n",
    "    \n",
    "    KL = tf.reduce_sum((alpha - beta)*(tf.digamma(alpha)-tf.digamma(S_alpha)),axis=1,keepdims=True) + \\\n",
    "         tf.lgamma(S_alpha) - tf.reduce_sum(tf.lgamma(alpha),axis=1,keepdims=True) + \\\n",
    "         tf.reduce_sum(tf.lgamma(beta),axis=1,keepdims=True) - tf.lgamma(tf.reduce_sum(beta,axis=1,keepdims=True))\n",
    "    return KL\n",
    "\n",
    "\n",
    "##### Loss functions (there are three different one defined in the papaer)\n",
    "\n",
    "def loss_eq5(p, alpha, K, global_step, annealing_step):  # MSE\n",
    "    S = tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
    "    loglikelihood = tf.reduce_sum((p-(alpha/S))**2, axis=1, keepdims=True) + tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keepdims=True)\n",
    "    KL_reg =  tf.minimum(1.0, tf.cast(global_step/annealing_step, tf.float32)) * KL((alpha - 1)*(1-p) + 1 , K)\n",
    "    return loglikelihood + KL_reg\n",
    "\n",
    "def loss_eq4(p, alpha, K, global_step, annealing_step):   #  expected cross entropy loss\n",
    "    loglikelihood = tf.reduce_mean(tf.reduce_sum(p * (tf.digamma(tf.reduce_sum(alpha, axis=1, keepdims=True)) - tf.digamma(alpha)), 1, keepdims=True))\n",
    "    KL_reg =  tf.minimum(1.0, tf.cast(global_step/annealing_step, tf.float32)) * KL((alpha - 1)*(1-p) + 1 , K)\n",
    "    return loglikelihood + KL_reg\n",
    "\n",
    "def loss_eq3(p, alpha, K, global_step, annealing_step):\n",
    "    loglikelihood = tf.reduce_mean(tf.reduce_sum(p * (tf.log(tf.reduce_sum(alpha, axis=1, keepdims=True)) - tf.log(alpha)), 1, keepdims=True))\n",
    "    KL_reg =  tf.minimum(1.0, tf.cast(global_step/annealing_step, tf.float32)) * KL((alpha - 1)*(1-p) + 1 , K)\n",
    "    return loglikelihood + KL_reg\n",
    "\n",
    "def mse_loss(p, alpha, K, global_step, annealing_step): \n",
    "    S = tf.reduce_sum(alpha, axis=1, keep_dims=True) \n",
    "    E = alpha - 1\n",
    "    m = alpha / S\n",
    "    \n",
    "    A = tf.reduce_sum((p-m)**2, axis=1, keep_dims=True) \n",
    "    B = tf.reduce_sum(alpha*(S-alpha)/(S*S*(S+1)), axis=1, keep_dims=True) \n",
    "    \n",
    "    annealing_coef = tf.minimum(1.0,tf.cast(global_step/annealing_step,tf.float32))\n",
    "    \n",
    "    alp = E*(1-p) + 1 \n",
    "    C =  annealing_coef * KL(alp, K)\n",
    "    return (A + B) + C\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels,n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start loading data\n",
      "Data loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "## GET DATA TO WORK ON\n",
    "print(\"Start loading data\")\n",
    "\n",
    "fd = open(\"data_x.pkl\", 'rb')\n",
    "fd2 = open(\"data_y.pkl\", 'rb')\n",
    "features = pickle.load(fd)\n",
    "labels = pickle.load(fd2)\n",
    "\n",
    "print(\"Data loaded\")\n",
    "\n",
    "# TRAIN - TEST\n",
    "p_train = 0.8\n",
    "\n",
    "rnd_indices = np.random.rand(len(labels)) < p_train\n",
    "X_train = features[rnd_indices]\n",
    "Y_train = labels[rnd_indices]\n",
    "X_test = features[~rnd_indices]\n",
    "Y_test = labels[~rnd_indices]\n",
    "\n",
    "X_train = X_train.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "\n",
    "\n",
    "## FIX FOR KERAS\n",
    "# Y_train = Y_train.reshape((-1, 1))\n",
    "# Y_test = Y_test.reshape((-1, 1))\n",
    "\n",
    "## one hot encoding\n",
    "Y_train = one_hot_encode(Y_train)\n",
    "Y_test = one_hot_encode(Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43285, 40, 40, 3)\n",
      "(43285, 10)\n",
      "(10869, 40, 40, 3)\n",
      "(10869, 10)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For batch of size 512: \n",
      " 84 batches in train \n",
      " 21 batches in test\n"
     ]
    }
   ],
   "source": [
    "# NETWORK PARAMETERS\n",
    "data_w = 40\n",
    "data_h = 40\n",
    "n_classes = 10\n",
    "n_filters_1 = 32\n",
    "n_filters_2 = 64\n",
    "d_filter = 3\n",
    "p_drop_1 = 0.25\n",
    "p_drop_2 = 0.50\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "K= n_classes\n",
    "num_channels = 3\n",
    "num_labels = n_classes\n",
    "\n",
    "n_batches = Y_train.shape[0]//batch_size\n",
    "n_batches_test = Y_test.shape[0]//batch_size\n",
    "print('For batch of size %d: \\n %d batches in train \\n %d batches in test'%(batch_size, n_batches, n_batches_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lmb = 0.00\n",
    "omega = 1.0\n",
    "regularizer = tf.contrib.layers.l2_regularizer(scale=omega)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-4-dd53bbe45d23>:55: calling reduce_sum (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n"
     ]
    }
   ],
   "source": [
    "# new network:\n",
    "\n",
    "X = tf.placeholder(tf.float32, shape=[None,data_w,data_h,num_channels], name = 'input')\n",
    "Y = tf.placeholder(tf.float32, shape=[None,num_labels], name = 'label')\n",
    "\n",
    "keep_prob = tf.placeholder(dtype=tf.float32, name = 'dropout_rate')\n",
    "global_step = tf.Variable(initial_value=0, name='global_step', trainable=False)\n",
    "annealing_step = tf.placeholder(dtype=tf.int32, name = 'annealing_step') \n",
    "\n",
    "### conv module\n",
    "\n",
    "# Convolutional Layer #1\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=X,\n",
    "    filters=32,\n",
    "    strides=(1, 1),\n",
    "    kernel_size=[3, 3],\n",
    "    kernel_regularizer=regularizer,\n",
    "    padding=\"valid\"\n",
    "    )\n",
    "conv1_act = tf.nn.relu( conv1 )\n",
    "# pool1 = tf.layers.max_pooling2d(inputs=act1, pool_size=[3, 3], strides=3)\n",
    "# dropout1 = tf.layers.dropout(\n",
    "#     inputs=pool1, rate=0.1)\n",
    "\n",
    "# Convolutional Layer #2\n",
    "conv2 = tf.layers.conv2d(\n",
    "    inputs=conv1_act,\n",
    "    filters=32,\n",
    "    strides=(1, 1),\n",
    "    kernel_size=[3, 3],\n",
    "    kernel_regularizer=regularizer,\n",
    "    padding=\"valid\"\n",
    "    )\n",
    "# bn2 = tf.layers.batch_normalization(\n",
    "#     conv2,\n",
    "#     axis=-1\n",
    "#     )\n",
    "conv2_act = tf.nn.relu( conv2 )\n",
    "conv2_mp = tf.layers.max_pooling2d(inputs=conv2_act, pool_size=[2, 2], strides=2)\n",
    "dpout1 = tf.layers.dropout(\n",
    "    inputs=conv2_mp, rate= p_drop_1)\n",
    "\n",
    "\n",
    "\n",
    "# Convolutional Layer #3\n",
    "conv3 = tf.layers.conv2d(\n",
    "    inputs=dpout1,\n",
    "    filters=64,\n",
    "    strides=(1, 1),\n",
    "    kernel_size=[3, 3],\n",
    "    kernel_regularizer=regularizer,\n",
    "    padding=\"valid\"\n",
    "    )\n",
    "conv3_act = tf.nn.relu( conv3 )\n",
    "\n",
    "# Convolutional Layer #4\n",
    "conv4 = tf.layers.conv2d(\n",
    "    inputs=conv1_act,\n",
    "    filters=64,\n",
    "    strides=(1, 1),\n",
    "    kernel_size=[3, 3],\n",
    "    kernel_regularizer=regularizer,\n",
    "    padding=\"valid\"\n",
    "    )\n",
    "# bn2 = tf.layers.batch_normalization(\n",
    "#     conv2,\n",
    "#     axis=-1\n",
    "#     )\n",
    "conv4_act = tf.nn.relu( conv4 )\n",
    "conv4_mp = tf.layers.max_pooling2d(inputs=conv4_act, pool_size=[2, 2], strides=2)\n",
    "dpout2 = tf.layers.dropout(\n",
    "    inputs=conv4_mp, rate= p_drop_1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### modify dimensions\n",
    "shape = dpout2.get_shape().as_list()\n",
    "flat1 = tf.reshape(dpout2, [-1, shape[1] * shape[2]* shape[3]])\n",
    "\n",
    "\n",
    "\n",
    "### dense module\n",
    "\n",
    "fc1 = tf.layers.dense(inputs=flat1, \n",
    "                          kernel_regularizer=regularizer,\n",
    "                          units=256)\n",
    "fc1_act = tf.nn.relu( fc1 )\n",
    "dpout3 = tf.layers.dropout(\n",
    "    inputs=fc1_act, rate= p_drop_2)\n",
    "\n",
    "# Logits Layer\n",
    "logits = tf.layers.dense(inputs=dpout3, \n",
    "                         kernel_regularizer=regularizer,\n",
    "                         units=n_classes,\n",
    "                         name = 'logits_tensor')\n",
    "\n",
    "\n",
    "y_ = tf.nn.softmax(logits,name=\"softmax_tensor\")\n",
    "\n",
    "\n",
    "prediction = tf.argmax(logits, 1)\n",
    "\n",
    "\n",
    "\n",
    "########### EDL extension ###########\n",
    " \n",
    "logits2evidence =  exp_evidence ############ modify this function:  relu_evidence  exp_evidence softplus\n",
    "\n",
    "evidence = logits2evidence(logits)\n",
    "alpha = evidence + 1\n",
    "\n",
    "u = K / tf.reduce_sum(alpha, axis=1, keepdims=True)\n",
    "\n",
    "prob = alpha/tf.reduce_sum(alpha, 1, keepdims=True) \n",
    "\n",
    "loss_function = mse_loss  ########### use 5th MSE loss equ: loss_eq5, loss_eq4, loss_eq3, mse_loss\n",
    "\n",
    "loss = tf.reduce_mean(loss_function(Y, alpha, K, global_step, annealing_step))\n",
    "l2_loss = tf.losses.get_regularization_loss() * lmb\n",
    "loss_func = loss + l2_loss\n",
    "\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=0.001).minimize(loss_func, global_step=global_step)\n",
    "\n",
    "match = tf.reshape(tf.cast(tf.equal(tf.argmax(logits, 1), tf.argmax(Y, 1)), tf.float32),(-1,1))\n",
    "accuracy = tf.reduce_mean(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 0.001\n",
    "training_iterations = 200\n",
    "\n",
    "saver = tf.train.Saver()\n",
    "model_save_path = \"SaveModel/best_model.ckpt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# training succeed when: adam, lr=0.001, lmb = 0(no l2 regularization), batch_size 256, iteration 200\n",
    "# use mse_loss and exp_logits function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 1 - 100% -0.541016) Training Loss: 0.0015 \t Accuracy: 0.4269\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.5121\n",
      "=================Performance improved from 0.0000 to 0.5121 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 2 - 100% -0.576172) Training Loss: 0.0013 \t Accuracy: 0.5580\n",
      "Testing:\t  Loss: 0.0012 \t Accuracy: 0.5934\n",
      "=================Performance improved from 0.5121 to 0.5934 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 3 - 100% -0.611328) Training Loss: 0.0012 \t Accuracy: 0.6101\n",
      "Testing:\t  Loss: 0.0012 \t Accuracy: 0.5943\n",
      "=================Performance improved from 0.5934 to 0.5943 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 4 - 100% -0.671875) Training Loss: 0.0011 \t Accuracy: 0.6478\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.6559\n",
      "=================Performance improved from 0.5943 to 0.6559 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 5 - 100% -0.687500) Training Loss: 0.0011 \t Accuracy: 0.6819\n",
      "Testing:\t  Loss: 0.0012 \t Accuracy: 0.6389\n",
      "epoch 6 - 100% -0.718750) Training Loss: 0.0010 \t Accuracy: 0.6919\n",
      "Testing:\t  Loss: 0.0012 \t Accuracy: 0.6504\n",
      "epoch 7 - 100% -0.730469) Training Loss: 0.0010 \t Accuracy: 0.7035\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.6578\n",
      "=================Performance improved from 0.6559 to 0.6578 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 8 - 100% -0.748047) Training Loss: 0.0010 \t Accuracy: 0.7121\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.6640\n",
      "=================Performance improved from 0.6578 to 0.6640 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 9 - 100% -0.761719) Training Loss: 0.0009 \t Accuracy: 0.7217\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.6760\n",
      "=================Performance improved from 0.6640 to 0.6760 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 10 - 100% -0.773438) Training Loss: 0.0009 \t Accuracy: 0.7305\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.6895\n",
      "=================Performance improved from 0.6760 to 0.6895 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 11 - 100% -0.824219) Training Loss: 0.0009 \t Accuracy: 0.7361\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7201\n",
      "=================Performance improved from 0.6895 to 0.7201 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 12 - 100% -0.835938) Training Loss: 0.0008 \t Accuracy: 0.7494\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7348\n",
      "=================Performance improved from 0.7201 to 0.7348 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 13 - 100% -0.845703) Training Loss: 0.0008 \t Accuracy: 0.7616\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.7328\n",
      "epoch 14 - 100% -0.851562) Training Loss: 0.0008 \t Accuracy: 0.7717\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7414\n",
      "=================Performance improved from 0.7348 to 0.7414 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 15 - 100% -0.845703) Training Loss: 0.0007 \t Accuracy: 0.7788\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7556\n",
      "=================Performance improved from 0.7414 to 0.7556 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 16 - 100% -0.818359) Training Loss: 0.0007 \t Accuracy: 0.7841\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.7465\n",
      "epoch 17 - 100% -0.824219) Training Loss: 0.0007 \t Accuracy: 0.7874\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7561\n",
      "=================Performance improved from 0.7556 to 0.7561 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 18 - 100% -0.853516) Training Loss: 0.0007 \t Accuracy: 0.7912\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7682\n",
      "=================Performance improved from 0.7561 to 0.7682 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 19 - 100% -0.867188) Training Loss: 0.0007 \t Accuracy: 0.7940\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7626\n",
      "epoch 20 - 100% -0.865234) Training Loss: 0.0007 \t Accuracy: 0.8002\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7636\n",
      "epoch 21 - 100% -0.867188) Training Loss: 0.0006 \t Accuracy: 0.8059\n",
      "Testing:\t  Loss: 0.0009 \t Accuracy: 0.7806\n",
      "=================Performance improved from 0.7682 to 0.7806 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 22 - 100% -0.867188) Training Loss: 0.0006 \t Accuracy: 0.8100\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7817\n",
      "=================Performance improved from 0.7806 to 0.7817 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 23 - 100% -0.884766) Training Loss: 0.0006 \t Accuracy: 0.8134\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7797\n",
      "epoch 24 - 100% -0.878906) Training Loss: 0.0006 \t Accuracy: 0.8166\n",
      "Testing:\t  Loss: 0.0009 \t Accuracy: 0.7932\n",
      "=================Performance improved from 0.7817 to 0.7932 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 25 - 100% -0.873047) Training Loss: 0.0006 \t Accuracy: 0.8199\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7985\n",
      "=================Performance improved from 0.7932 to 0.7985 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 26 - 100% -0.873047) Training Loss: 0.0006 \t Accuracy: 0.8175\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.7889\n",
      "epoch 27 - 100% -0.869141) Training Loss: 0.0005 \t Accuracy: 0.8275\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.7958\n",
      "epoch 28 - 100% -0.869141) Training Loss: 0.0005 \t Accuracy: 0.8272\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.8000\n",
      "=================Performance improved from 0.7985 to 0.8000 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 29 - 100% -0.886719) Training Loss: 0.0005 \t Accuracy: 0.8349\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.8120\n",
      "=================Performance improved from 0.8000 to 0.8120 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 30 - 100% -0.884766) Training Loss: 0.0005 \t Accuracy: 0.8395\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.8112\n",
      "epoch 31 - 100% -0.888672) Training Loss: 0.0005 \t Accuracy: 0.8431\n",
      "Testing:\t  Loss: 0.0009 \t Accuracy: 0.8128\n",
      "=================Performance improved from 0.8120 to 0.8128 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 32 - 100% -0.900391) Training Loss: 0.0005 \t Accuracy: 0.8485\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.8227\n",
      "=================Performance improved from 0.8128 to 0.8227 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 33 - 100% -0.906250) Training Loss: 0.0005 \t Accuracy: 0.8497\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.8220\n",
      "epoch 34 - 100% -0.925781) Training Loss: 0.0005 \t Accuracy: 0.8513\n",
      "Testing:\t  Loss: 0.0009 \t Accuracy: 0.8278\n",
      "=================Performance improved from 0.8227 to 0.8278 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 35 - 100% -0.914062) Training Loss: 0.0004 \t Accuracy: 0.8599\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.8293\n",
      "=================Performance improved from 0.8278 to 0.8293 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 36 - 100% -0.923828) Training Loss: 0.0004 \t Accuracy: 0.8632\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.8372\n",
      "=================Performance improved from 0.8293 to 0.8372 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 37 - 100% -0.923828) Training Loss: 0.0004 \t Accuracy: 0.8641\n",
      "Testing:\t  Loss: 0.0010 \t Accuracy: 0.8299\n",
      "epoch 38 - 100% -0.919922) Training Loss: 0.0004 \t Accuracy: 0.8692\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.8305\n",
      "epoch 39 - 100% -0.921875) Training Loss: 0.0004 \t Accuracy: 0.8707\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8353\n",
      "epoch 40 - 100% -0.919922) Training Loss: 0.0004 \t Accuracy: 0.8724\n",
      "Testing:\t  Loss: 0.0012 \t Accuracy: 0.8383\n",
      "=================Performance improved from 0.8372 to 0.8383 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 41 - 100% -0.927734) Training Loss: 0.0003 \t Accuracy: 0.8790\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8403\n",
      "=================Performance improved from 0.8383 to 0.8403 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 42 - 100% -0.929688) Training Loss: 0.0003 \t Accuracy: 0.8794\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8503\n",
      "=================Performance improved from 0.8403 to 0.8503 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 43 - 100% -0.929688) Training Loss: 0.0003 \t Accuracy: 0.8805\n",
      "Testing:\t  Loss: 0.0014 \t Accuracy: 0.8459\n",
      "epoch 44 - 100% -0.923828) Training Loss: 0.0003 \t Accuracy: 0.8814\n",
      "Testing:\t  Loss: 0.0012 \t Accuracy: 0.8443\n",
      "epoch 45 - 100% -0.914062) Training Loss: 0.0003 \t Accuracy: 0.8843\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8420\n",
      "epoch 46 - 100% -0.917969) Training Loss: 0.0003 \t Accuracy: 0.8811\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8384\n",
      "epoch 47 - 100% -0.923828) Training Loss: 0.0003 \t Accuracy: 0.8888\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8436\n",
      "epoch 48 - 100% -0.929688) Training Loss: 0.0003 \t Accuracy: 0.8918\n",
      "Testing:\t  Loss: 0.0014 \t Accuracy: 0.8414\n",
      "epoch 49 - 100% -0.925781) Training Loss: 0.0003 \t Accuracy: 0.8938\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8389\n",
      "epoch 50 - 100% -0.931641) Training Loss: 0.0003 \t Accuracy: 0.8934\n",
      "Testing:\t  Loss: 0.0014 \t Accuracy: 0.8523\n",
      "=================Performance improved from 0.8503 to 0.8523 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 51 - 100% -0.927734) Training Loss: 0.0003 \t Accuracy: 0.8934\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8416\n",
      "epoch 52 - 100% -0.925781) Training Loss: 0.0003 \t Accuracy: 0.8919\n",
      "Testing:\t  Loss: 0.0015 \t Accuracy: 0.8377\n",
      "epoch 53 - 100% -0.937500) Training Loss: 0.0003 \t Accuracy: 0.8957\n",
      "Testing:\t  Loss: 0.0015 \t Accuracy: 0.8538\n",
      "=================Performance improved from 0.8523 to 0.8538 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 54 - 100% -0.937500) Training Loss: 0.0003 \t Accuracy: 0.8968\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.8663\n",
      "=================Performance improved from 0.8538 to 0.8663 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 55 - 100% -0.933594) Training Loss: 0.0003 \t Accuracy: 0.8959\n",
      "Testing:\t  Loss: 0.0012 \t Accuracy: 0.8510\n",
      "epoch 56 - 100% -0.941406) Training Loss: 0.0003 \t Accuracy: 0.8974\n",
      "Testing:\t  Loss: 0.0011 \t Accuracy: 0.8650\n",
      "epoch 57 - 100% -0.931641) Training Loss: 0.0003 \t Accuracy: 0.8991\n",
      "Testing:\t  Loss: 0.0013 \t Accuracy: 0.8623\n",
      "epoch 58 - 100% -0.941406) Training Loss: 0.0003 \t Accuracy: 0.9013\n",
      "Testing:\t  Loss: 0.0014 \t Accuracy: 0.8643\n",
      "epoch 59 - 100% -0.941406) Training Loss: 0.0003 \t Accuracy: 0.9037\n",
      "Testing:\t  Loss: 0.0014 \t Accuracy: 0.8630\n",
      "epoch 60 - 100% -0.933594) Training Loss: 0.0003 \t Accuracy: 0.9041\n",
      "Testing:\t  Loss: 0.0017 \t Accuracy: 0.8638\n",
      "epoch 61 - 100% -0.941406) Training Loss: 0.0002 \t Accuracy: 0.9068\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8721\n",
      "=================Performance improved from 0.8663 to 0.8721 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 62 - 100% -0.941406) Training Loss: 0.0002 \t Accuracy: 0.9075\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8670\n",
      "epoch 63 - 100% -0.943359) Training Loss: 0.0002 \t Accuracy: 0.9099\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8647\n",
      "epoch 64 - 100% -0.947266) Training Loss: 0.0002 \t Accuracy: 0.9107\n",
      "Testing:\t  Loss: 0.0015 \t Accuracy: 0.8725\n",
      "=================Performance improved from 0.8721 to 0.8725 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 65 - 100% -0.957031) Training Loss: 0.0003 \t Accuracy: 0.9090\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8760\n",
      "=================Performance improved from 0.8725 to 0.8760 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 66 - 100% -0.957031) Training Loss: 0.0002 \t Accuracy: 0.9143\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8733\n",
      "epoch 67 - 100% -0.953125) Training Loss: 0.0003 \t Accuracy: 0.9116\n",
      "Testing:\t  Loss: 0.0015 \t Accuracy: 0.8615\n",
      "epoch 68 - 100% -0.951172) Training Loss: 0.0003 \t Accuracy: 0.9108\n",
      "Testing:\t  Loss: 0.0015 \t Accuracy: 0.8656\n",
      "epoch 69 - 100% -0.955078) Training Loss: 0.0003 \t Accuracy: 0.9109\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8713\n",
      "epoch 70 - 100% -0.957031) Training Loss: 0.0003 \t Accuracy: 0.9114\n",
      "Testing:\t  Loss: 0.0017 \t Accuracy: 0.8664\n",
      "epoch 71 - 100% -0.960938) Training Loss: 0.0003 \t Accuracy: 0.9121\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8743\n",
      "epoch 72 - 100% -0.960938) Training Loss: 0.0002 \t Accuracy: 0.9146\n",
      "Testing:\t  Loss: 0.0017 \t Accuracy: 0.8780\n",
      "=================Performance improved from 0.8760 to 0.8780 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 73 - 100% -0.962891) Training Loss: 0.0002 \t Accuracy: 0.9154\n",
      "Testing:\t  Loss: 0.0017 \t Accuracy: 0.8757\n",
      "epoch 74 - 100% -0.960938) Training Loss: 0.0002 \t Accuracy: 0.9175\n",
      "Testing:\t  Loss: 0.0016 \t Accuracy: 0.8788\n",
      "=================Performance improved from 0.8780 to 0.8788 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 75 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9196\n",
      "Testing:\t  Loss: 0.0017 \t Accuracy: 0.8802\n",
      "=================Performance improved from 0.8788 to 0.8802 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 76 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9200\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8812\n",
      "=================Performance improved from 0.8802 to 0.8812 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 77 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9224\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8797\n",
      "epoch 78 - 100% -0.962891) Training Loss: 0.0002 \t Accuracy: 0.9205\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8818\n",
      "=================Performance improved from 0.8812 to 0.8818 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 79 - 100% -0.957031) Training Loss: 0.0002 \t Accuracy: 0.9185\n",
      "Testing:\t  Loss: 0.0024 \t Accuracy: 0.8656\n",
      "epoch 80 - 100% -0.958984) Training Loss: 0.0003 \t Accuracy: 0.9045\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8652\n",
      "epoch 81 - 100% -0.968750) Training Loss: 0.0003 \t Accuracy: 0.9116\n",
      "Testing:\t  Loss: 0.0017 \t Accuracy: 0.8656\n",
      "epoch 82 - 100% -0.960938) Training Loss: 0.0002 \t Accuracy: 0.9168\n",
      "Testing:\t  Loss: 0.0018 \t Accuracy: 0.8712\n",
      "epoch 83 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9180\n",
      "Testing:\t  Loss: 0.0020 \t Accuracy: 0.8782\n",
      "epoch 84 - 100% -0.964844) Training Loss: 0.0003 \t Accuracy: 0.9126\n",
      "Testing:\t  Loss: 0.0018 \t Accuracy: 0.8713\n",
      "epoch 85 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9174\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8734\n",
      "epoch 86 - 100% -0.964844) Training Loss: 0.0003 \t Accuracy: 0.9172\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8781\n",
      "epoch 87 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9202\n",
      "Testing:\t  Loss: 0.0020 \t Accuracy: 0.8778\n",
      "epoch 88 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9209\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8817\n",
      "epoch 89 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9227\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8830\n",
      "=================Performance improved from 0.8818 to 0.8830 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 90 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9231\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8850\n",
      "=================Performance improved from 0.8830 to 0.8850 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 91 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9240\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8852\n",
      "=================Performance improved from 0.8850 to 0.8852 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 92 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9247\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8858\n",
      "=================Performance improved from 0.8852 to 0.8858 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 93 - 100% -0.974609) Training Loss: 0.0002 \t Accuracy: 0.9246\n",
      "Testing:\t  Loss: 0.0028 \t Accuracy: 0.8857\n",
      "epoch 94 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9255\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8850\n",
      "epoch 95 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9255\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8858\n",
      "epoch 96 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9256\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8880\n",
      "=================Performance improved from 0.8858 to 0.8880 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 97 - 100% -0.974609) Training Loss: 0.0002 \t Accuracy: 0.9259\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8894\n",
      "=================Performance improved from 0.8880 to 0.8894 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 98 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9262\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8904\n",
      "=================Performance improved from 0.8894 to 0.8904 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 99 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9265\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8909\n",
      "=================Performance improved from 0.8904 to 0.8909 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 100 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9271\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8891\n",
      "epoch 101 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9262\n",
      "Testing:\t  Loss: 0.0020 \t Accuracy: 0.8844\n",
      "epoch 102 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9260\n",
      "Testing:\t  Loss: 0.0029 \t Accuracy: 0.8846\n",
      "epoch 103 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9254\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8789\n",
      "epoch 104 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9257\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8824\n",
      "epoch 105 - 100% -0.957031) Training Loss: 0.0002 \t Accuracy: 0.9248\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8846\n",
      "epoch 106 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9236\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8843\n",
      "epoch 107 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9248\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8794\n",
      "epoch 108 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9260\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8876\n",
      "epoch 109 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9245\n",
      "Testing:\t  Loss: 0.0018 \t Accuracy: 0.8795\n",
      "epoch 110 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9256\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8808\n",
      "epoch 111 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9267\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8894\n",
      "epoch 112 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9275\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8843\n",
      "epoch 113 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9272\n",
      "Testing:\t  Loss: 0.0024 \t Accuracy: 0.8854\n",
      "epoch 114 - 100% -0.958984) Training Loss: 0.0002 \t Accuracy: 0.9246\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8676\n",
      "epoch 115 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9251\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8856\n",
      "epoch 116 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9271\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8860\n",
      "epoch 117 - 100% -0.958984) Training Loss: 0.0002 \t Accuracy: 0.9248\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8837\n",
      "epoch 118 - 100% -0.953125) Training Loss: 0.0002 \t Accuracy: 0.9251\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8702\n",
      "epoch 119 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9268\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8879\n",
      "epoch 120 - 100% -0.962891) Training Loss: 0.0002 \t Accuracy: 0.9288\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8883\n",
      "epoch 121 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9289\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8859\n",
      "epoch 122 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9294\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8927\n",
      "=================Performance improved from 0.8909 to 0.8927 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 123 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9299\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8941\n",
      "=================Performance improved from 0.8927 to 0.8941 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 124 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9295\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8951\n",
      "=================Performance improved from 0.8941 to 0.8951 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 125 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9299\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8918\n",
      "epoch 126 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9307\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8943\n",
      "epoch 127 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9305\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8953\n",
      "=================Performance improved from 0.8951 to 0.8953 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 128 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9309\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8955\n",
      "=================Performance improved from 0.8953 to 0.8955 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 129 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9311\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8950\n",
      "epoch 130 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9318\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8957\n",
      "=================Performance improved from 0.8955 to 0.8957 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 131 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9317\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8958\n",
      "=================Performance improved from 0.8957 to 0.8958 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 132 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9323\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8968\n",
      "=================Performance improved from 0.8958 to 0.8968 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 133 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9325\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8969\n",
      "=================Performance improved from 0.8968 to 0.8969 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 134 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9328\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8976\n",
      "=================Performance improved from 0.8969 to 0.8976 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 135 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9331\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8982\n",
      "=================Performance improved from 0.8976 to 0.8982 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 136 - 100% -0.966797) Training Loss: 0.0001 \t Accuracy: 0.9338\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8978\n",
      "epoch 137 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9324\n",
      "Testing:\t  Loss: 0.0024 \t Accuracy: 0.8921\n",
      "epoch 138 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9331\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8973\n",
      "epoch 139 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9336\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8966\n",
      "epoch 140 - 100% -0.966797) Training Loss: 0.0001 \t Accuracy: 0.9342\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8975\n",
      "epoch 141 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9331\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8931\n",
      "epoch 142 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9318\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8900\n",
      "epoch 143 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9318\n",
      "Testing:\t  Loss: 0.0020 \t Accuracy: 0.8873\n",
      "epoch 144 - 100% -0.966797) Training Loss: 0.0003 \t Accuracy: 0.9275\n",
      "Testing:\t  Loss: 0.0020 \t Accuracy: 0.8809\n",
      "epoch 145 - 100% -0.966797) Training Loss: 0.0003 \t Accuracy: 0.9259\n",
      "Testing:\t  Loss: 0.0017 \t Accuracy: 0.8792\n",
      "epoch 146 - 100% -0.937500) Training Loss: 0.0003 \t Accuracy: 0.9245\n",
      "Testing:\t  Loss: 0.0018 \t Accuracy: 0.8656\n",
      "epoch 147 - 100% -0.964844) Training Loss: 0.0002 \t Accuracy: 0.9290\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8833\n",
      "epoch 148 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9322\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8914\n",
      "epoch 149 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9328\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8884\n",
      "epoch 150 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9312\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8897\n",
      "epoch 151 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9332\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8953\n",
      "epoch 152 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9335\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8960\n",
      "epoch 153 - 100% -0.966797) Training Loss: 0.0002 \t Accuracy: 0.9342\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8946\n",
      "epoch 154 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9349\n",
      "Testing:\t  Loss: 0.0024 \t Accuracy: 0.8961\n",
      "epoch 155 - 100% -0.966797) Training Loss: 0.0001 \t Accuracy: 0.9354\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8943\n",
      "epoch 156 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8969\n",
      "epoch 157 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9357\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8965\n",
      "epoch 158 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9359\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8970\n",
      "epoch 159 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9362\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8969\n",
      "epoch 160 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9358\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8977\n",
      "epoch 161 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9350\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8963\n",
      "epoch 162 - 100% -0.972656) Training Loss: 0.0002 \t Accuracy: 0.9360\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8936\n",
      "epoch 163 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9357\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8984\n",
      "=================Performance improved from 0.8982 to 0.8984 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 164 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9361\n",
      "Testing:\t  Loss: 0.0024 \t Accuracy: 0.8979\n",
      "epoch 165 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9365\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8993\n",
      "=================Performance improved from 0.8984 to 0.8993 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 166 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9367\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8994\n",
      "=================Performance improved from 0.8993 to 0.8994 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 167 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9367\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8989\n",
      "epoch 168 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9367\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8996\n",
      "=================Performance improved from 0.8994 to 0.8996 !================= \n",
      "Model saved in path: SaveModel/best_model.ckpt\n",
      "epoch 169 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9370\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8988\n",
      "epoch 170 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9370\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8987\n",
      "epoch 171 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9371\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8996\n",
      "epoch 172 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9372\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8983\n",
      "epoch 173 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9374\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8990\n",
      "epoch 174 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9376\n",
      "Testing:\t  Loss: 0.0028 \t Accuracy: 0.8983\n",
      "epoch 175 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9371\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8987\n",
      "epoch 176 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9372\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8910\n",
      "epoch 177 - 100% -0.960938) Training Loss: 0.0002 \t Accuracy: 0.9341\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8844\n",
      "epoch 178 - 100% -0.960938) Training Loss: 0.0003 \t Accuracy: 0.9233\n",
      "Testing:\t  Loss: 0.0020 \t Accuracy: 0.8789\n",
      "epoch 179 - 100% -0.964844) Training Loss: 0.0003 \t Accuracy: 0.9280\n",
      "Testing:\t  Loss: 0.0019 \t Accuracy: 0.8819\n",
      "epoch 180 - 100% -0.962891) Training Loss: 0.0002 \t Accuracy: 0.9331\n",
      "Testing:\t  Loss: 0.0018 \t Accuracy: 0.8876\n",
      "epoch 181 - 100% -0.968750) Training Loss: 0.0002 \t Accuracy: 0.9345\n",
      "Testing:\t  Loss: 0.0021 \t Accuracy: 0.8868\n",
      "epoch 182 - 100% -0.970703) Training Loss: 0.0002 \t Accuracy: 0.9349\n",
      "Testing:\t  Loss: 0.0022 \t Accuracy: 0.8938\n",
      "epoch 183 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9361\n",
      "Testing:\t  Loss: 0.0023 \t Accuracy: 0.8950\n",
      "epoch 184 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9368\n",
      "Testing:\t  Loss: 0.0024 \t Accuracy: 0.8956\n",
      "epoch 185 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9368\n",
      "Testing:\t  Loss: 0.0024 \t Accuracy: 0.8967\n",
      "epoch 186 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9366\n",
      "Testing:\t  Loss: 0.0025 \t Accuracy: 0.8972\n",
      "epoch 187 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9370\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8969\n",
      "epoch 188 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9374\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8967\n",
      "epoch 189 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9375\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8968\n",
      "epoch 190 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9377\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8969\n",
      "epoch 191 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9379\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8971\n",
      "epoch 192 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9379\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8977\n",
      "epoch 193 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9377\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8972\n",
      "epoch 194 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9381\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8971\n",
      "epoch 195 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9381\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8983\n",
      "epoch 196 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9384\n",
      "Testing:\t  Loss: 0.0026 \t Accuracy: 0.8982\n",
      "epoch 197 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9383\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8983\n",
      "epoch 198 - 100% -0.970703) Training Loss: 0.0001 \t Accuracy: 0.9382\n",
      "Testing:\t  Loss: 0.0027 \t Accuracy: 0.8987\n",
      "epoch 199 - 100% -0.968750) Training Loss: 0.0001 \t Accuracy: 0.9382\n",
      "Testing:\t  Loss: 0.0028 \t Accuracy: 0.8987\n",
      "epoch 200 - 100% -0.972656) Training Loss: 0.0001 \t Accuracy: 0.9383\n",
      "Testing:\t  Loss: 0.0028 \t Accuracy: 0.8982\n"
     ]
    }
   ],
   "source": [
    "cost_train = []\n",
    "cost_test = []\n",
    "acc_train = []\n",
    "acc_test = []\n",
    "\n",
    "best_acc = 0\n",
    "\n",
    "session =  tf.Session(config=config)\n",
    "session.run(tf.global_variables_initializer())\n",
    "\n",
    "# with tf.Session(config=config) as session:\n",
    "#     tf.global_variables_initializer().run()\n",
    "\n",
    "for itr in range(training_iterations):  \n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "    for i in range(n_batches):\n",
    "        offset = (i * batch_size) % (Y_train.shape[0] - batch_size)\n",
    "        batch_x = X_train[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = Y_train[offset:(offset + batch_size), :]\n",
    "\n",
    "        _, c, acc = session.run([optimizer, loss_func, accuracy],feed_dict={X: batch_x, Y : batch_y, keep_prob:.5, annealing_step:100*n_batches})\n",
    "        print('epoch %d - %d%% -%f) '% (itr+1, (100*(i+1))//n_batches, acc), end='\\r' if i<n_batches-1 else '')\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(c)\n",
    "    train_acc = np.array(np.array(acc_list).mean())\n",
    "    train_loss = np.array(np.array(loss_list).sum())\n",
    "    print('Training Loss: %2.4f \\t Accuracy: %2.4f' % (train_loss/Y_train.shape[0], train_acc))\n",
    "\n",
    "\n",
    "#       Performance on testing dataset:\n",
    "    acc_list = []\n",
    "    loss_list = []\n",
    "    for i in range(n_batches_test):\n",
    "        offset = (i * batch_size) % (Y_test.shape[0] - batch_size)\n",
    "        batch_x = X_test[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = Y_test[offset:(offset + batch_size), :]\n",
    "\n",
    "        c, acc = session.run([loss_func, accuracy],feed_dict={X: batch_x, Y : batch_y, keep_prob:1.,  annealing_step:100*n_batches})\n",
    "#             print('epoch %d - %d%% -%f) '% (itr+1, (100*(i+1))//n_batches, c), end='\\r' if i<n_batches-1 else '')\n",
    "        acc_list.append(acc)\n",
    "        loss_list.append(c)\n",
    "    test_acc = np.array(np.array(acc_list).mean())\n",
    "    test_loss = np.array(np.array(loss_list).sum())\n",
    "    print('Testing:\\t  Loss: %2.4f \\t Accuracy: %2.4f' % (test_loss/Y_test.shape[0], test_acc))\n",
    "\n",
    "    cost_train.append(train_loss)\n",
    "    cost_test.append(test_loss)\n",
    "    acc_train.append(train_acc)\n",
    "    acc_test.append(test_acc)\n",
    "    \n",
    "    \n",
    "    # save best model if necessary:\n",
    "    if test_acc > best_acc:\n",
    "        print('=================Performance improved from %.4f to %.4f !================= '%(best_acc, test_acc))\n",
    "        save_path = saver.save(session, model_save_path)\n",
    "        print(\"Model saved in path: %s\" % save_path)\n",
    "        best_acc = test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 648x216 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# cost_train\n",
    "# cost_test\n",
    "# acc_train\n",
    "# acc_test\n",
    "fig = plt.figure(figsize=(9,3))\n",
    "plt.plot(cost_train, 'r-')\n",
    "plt.plot(cost_test, 'b-')\n",
    "\n",
    "# plt.axis([0,training_iterations,0,np.max(cost_history)])\n",
    "plt.show()\n",
    "\n",
    "\n",
    "fig = plt.figure(figsize=(9,3))\n",
    "plt.plot(acc_train, 'r-')\n",
    "plt.plot(acc_test, 'b-')\n",
    "# plt.axis([0,training_iterations,0,np.max(cost_history)])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Restore the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from SaveModel/best_model.ckpt\n",
      "Model restored.\n"
     ]
    }
   ],
   "source": [
    "# Add ops to save and restore all the variables.\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "session =  tf.Session()\n",
    "\n",
    "saver.restore(session, model_save_path)\n",
    "print(\"Model restored.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 - 100% -0.918919) Testing:\t  Loss: 0.0026 \t Accuracy: 0.8995\n"
     ]
    }
   ],
   "source": [
    "pred_y_list = np.zeros(0)\n",
    "\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "\n",
    "#       Performance on testing dataset:\n",
    "for i in range(n_batches_test):\n",
    "    if i == n_batches_test-1:\n",
    "        batch_x = X_test[i * batch_size:, :, :, :]\n",
    "        batch_y = Y_test[i * batch_size:, :]\n",
    "    else:\n",
    "        offset = (i * batch_size) % (Y_test.shape[0] - batch_size)\n",
    "        batch_x = X_test[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = Y_test[offset:(offset + batch_size), :]\n",
    "\n",
    "#     logits, y_pred = session.run([logits, prediction], feed_dict={X: batch_x, Y : batch_y})\n",
    "    y_pred, acc, c = session.run([prediction, accuracy, loss_func], feed_dict={X: batch_x, Y : batch_y, keep_prob:1.,  annealing_step:100*n_batches})\n",
    "\n",
    "    print('epoch %d - %d%% -%f) '% (i+1, (100*(i+1))//n_batches_test, acc), end='\\r' if i<n_batches_test-1 else '')\n",
    "#     y_pred = np.argmax(logits, axis=1)\n",
    "#     pred_y_list.append(y_pred)\n",
    "    pred_y_list = np.concatenate([pred_y_list, y_pred])\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    loss_list.append(c)\n",
    "#     test_acc = np.array(np.array(acc_list).mean())\n",
    "#     test_loss = np.array(np.array(loss_list).sum())\n",
    "    \n",
    "\n",
    "test_acc = np.array(np.array(acc_list).mean())\n",
    "test_loss = np.array(np.array(loss_list).sum())\n",
    "print('Testing:\\t  Loss: %2.4f \\t Accuracy: %2.4f' % (test_loss/Y_test.shape[0], test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_true = np.argmax(Y_test, 1)\n",
    "y_pred =pred_y_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on testing data: 0.8997147851688287\n",
      "[[1233    1   22   24   33    2    3    7   17   23]\n",
      " [   1  304    6    1    1    2    0    3    0    6]\n",
      " [  10    0 1215   58    3    8    2    0   11  102]\n",
      " [  12    1   66 1004    9    5    3    8   12   21]\n",
      " [   6    4   20   16 1082    2    5   31    6   26]\n",
      " [  50    7   11   38    7 1147   28   54   11   21]\n",
      " [   0    0    4    8    3    2  133    0    0    1]\n",
      " [   5    1    3    6    3    2    1 1204    0   12]\n",
      " [   2    0   19    8    1    3    1    2 1245    6]\n",
      " [  20    5   79   28    7    5    0   12   15 1212]]\n",
      "the mean-f1 score: 0.89\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "\n",
    "\n",
    "print('Accuracy on testing data:',sum(y_pred==y_true)/y_true.shape[0])\n",
    "cf_matrix = confusion_matrix(y_true, y_pred)\n",
    "print(cf_matrix)\n",
    "class_wise_f1 = np.round(f1_score(y_true, y_pred, average=None)*100)*0.01\n",
    "print('the mean-f1 score: {:.2f}'.format(np.mean(class_wise_f1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Uncertainty output:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 21 - 100% -0.918919) Testing:\t  Loss: 0.0026 \t Accuracy: 0.8995\n"
     ]
    }
   ],
   "source": [
    "pred_y_list = np.zeros(0)\n",
    "uncertainty_y_list = np.zeros([0,1])\n",
    "\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "\n",
    "#       Performance on testing dataset:\n",
    "for i in range(n_batches_test):\n",
    "    if i == n_batches_test-1:\n",
    "        batch_x = X_test[i * batch_size:, :, :, :]\n",
    "        batch_y = Y_test[i * batch_size:, :]\n",
    "    else:\n",
    "        offset = (i * batch_size) % (Y_test.shape[0] - batch_size)\n",
    "        batch_x = X_test[offset:(offset + batch_size), :, :, :]\n",
    "        batch_y = Y_test[offset:(offset + batch_size), :]\n",
    "\n",
    "#     logits, y_pred = session.run([logits, prediction], feed_dict={X: batch_x, Y : batch_y})\n",
    "    y_pred, acc, c, uncertainty = session.run([prediction, accuracy, loss_func, u], feed_dict={X: batch_x, Y : batch_y, keep_prob:1.,  annealing_step:100*n_batches})\n",
    "\n",
    "    print('epoch %d - %d%% -%f) '% (i+1, (100*(i+1))//n_batches_test, acc), end='\\r' if i<n_batches_test-1 else '')\n",
    "#     y_pred = np.argmax(logits, axis=1)\n",
    "#     pred_y_list.append(y_pred)\n",
    "    pred_y_list = np.concatenate([pred_y_list, y_pred])\n",
    "    uncertainty_y_list = np.concatenate([uncertainty_y_list, uncertainty])\n",
    "    \n",
    "    acc_list.append(acc)\n",
    "    loss_list.append(c)\n",
    "#     test_acc = np.array(np.array(acc_list).mean())\n",
    "#     test_loss = np.array(np.array(loss_list).sum())\n",
    "    \n",
    "\n",
    "test_acc = np.array(np.array(acc_list).mean())\n",
    "test_loss = np.array(np.array(loss_list).sum())\n",
    "print('Testing:\\t  Loss: %2.4f \\t Accuracy: %2.4f' % (test_loss/Y_test.shape[0], test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True \t Predict  Uncertainty \t Match:\n",
      "3 \t 3.0 \t [0.12549192]\n",
      "3 \t 3.0 \t [0.00045379]\n",
      "5 \t 9.0 \t [0.9929685] \t!!!\n",
      "8 \t 8.0 \t [0.00045379]\n",
      "4 \t 4.0 \t [0.00045379]\n",
      "0 \t 0.0 \t [0.00045379]\n",
      "0 \t 0.0 \t [0.00045379]\n",
      "4 \t 4.0 \t [0.00045379]\n",
      "0 \t 2.0 \t [0.99995458] \t!!!\n",
      "3 \t 3.0 \t [0.00041275]\n",
      "4 \t 4.0 \t [0.00045379]\n",
      "4 \t 4.0 \t [0.00045379]\n",
      "1 \t 1.0 \t [0.00045379]\n",
      "9 \t 2.0 \t [0.99986488] \t!!!\n",
      "8 \t 8.0 \t [0.00045379]\n",
      "0 \t 0.0 \t [0.00045379]\n",
      "8 \t 8.0 \t [0.00045379]\n",
      "8 \t 8.0 \t [0.00045379]\n",
      "0 \t 3.0 \t [0.99995458] \t!!!\n",
      "7 \t 7.0 \t [0.00045379]\n"
     ]
    }
   ],
   "source": [
    "print('True \\t Predict  Uncertainty \\t Match:')\n",
    "for i in range(20):\n",
    "# for i in range(pred_y_list.shape[0]):\n",
    "    if np.argmax(Y_test[i]) != pred_y_list[i]:\n",
    "        print(np.argmax(Y_test[i]), '\\t', pred_y_list[i], '\\t', uncertainty_y_list[i], '\\t!!!')\n",
    "    else:\n",
    "        print(np.argmax(Y_test[i]), '\\t', pred_y_list[i], '\\t', uncertainty_y_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
